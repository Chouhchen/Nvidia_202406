{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d3527c9-292f-4530-9e49-2bde2a67d529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (1.33.0)\n",
      "Requirement already satisfied: langchain in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (0.2.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: sniffio in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from openai) (2.0.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from openai) (4.7.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from langchain) (8.3.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from langchain) (0.1.75)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from langchain) (0.2.5)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from langchain) (2.28.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from langchain) (1.21.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from langchain) (0.2.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (21.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Requirement already satisfied: certifi in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2022.9.24)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.3.0 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (2.3.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2->langchain) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from SQLAlchemy<3,>=1.4->langchain) (1.1.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain) (2.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee5846db-8752-4ac8-a5a9-d00d05cf4538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-nvidia-ai-endpoints in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (0.1.2)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.0.0 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from langchain-nvidia-ai-endpoints) (10.3.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from langchain-nvidia-ai-endpoints) (3.9.5)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.1.27 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from langchain-nvidia-ai-endpoints) (0.2.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (1.9.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (21.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (1.3.1)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from langchain-core<0.3,>=0.1.27->langchain-nvidia-ai-endpoints) (23.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from langchain-core<0.3,>=0.1.27->langchain-nvidia-ai-endpoints) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.66 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from langchain-core<0.3,>=0.1.27->langchain-nvidia-ai-endpoints) (0.1.75)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from langchain-core<0.3,>=0.1.27->langchain-nvidia-ai-endpoints) (2.0.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from langchain-core<0.3,>=0.1.27->langchain-nvidia-ai-endpoints) (6.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from langchain-core<0.3,>=0.1.27->langchain-nvidia-ai-endpoints) (8.3.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.27->langchain-nvidia-ai-endpoints) (2.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.1.27->langchain-nvidia-ai-endpoints) (2.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.1.27->langchain-nvidia-ai-endpoints) (3.10.3)\n",
      "Requirement already satisfied: pydantic-core==2.3.0 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.27->langchain-nvidia-ai-endpoints) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.27->langchain-nvidia-ai-endpoints) (4.7.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.27->langchain-nvidia-ai-endpoints) (0.5.0)\n",
      "Requirement already satisfied: idna>=2.0 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from yarl<2.0,>=1.0->aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.1.27->langchain-nvidia-ai-endpoints) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.1.27->langchain-nvidia-ai-endpoints) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.1.27->langchain-nvidia-ai-endpoints) (2.0.4)\n",
      "Requirement already satisfied: PyPDF2 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (3.0.1)\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in /Users/hchou/opt/anaconda3/lib/python3.9/site-packages (from PyPDF2) (4.7.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade --quiet langchain-nvidia-ai-endpoints\n",
    "! pip install langchain-nvidia-ai-endpoints\n",
    "! pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "082ac2d7-f7a2-40c0-9abf-10a8dc80f64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "# from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "import getpass\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0215bbbf-e4ec-4ab0-b819-77d04de61c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.environ.get(\"NVIDIA_API_KEY\", \"\").startswith(\"nvapi-\"):\n",
    "    print(\"Valid NVIDIA_API_KEY already in environment. Delete to reset\")\n",
    "else:\n",
    "    nvapi_key = getpass.getpass(\"NVAPI Key (starts with nvapi-): \")\n",
    "    assert nvapi_key.startswith(\"nvapi-\"), f\"{nvapi_key[:5]}... is not a valid key\"\n",
    "    os.environ[\"NVIDIA_API_KEY\"] = nvapi_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "941ca01f-bc33-4c96-ab87-01f48986accb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hcchou\\AppData\\Local\\anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "#client = OpenAI(\n",
    "#  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
    "#  api_key = \"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\"\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf30c19-9b44-4597-8749-ba67b137001a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://python.langchain.com/v0.2/docs/integrations/chat/nvidia_ai_endpoints/\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af285528-4d5e-42c3-826c-46c99087eb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  In June, Taiwan'лле bunch of rain. It's like a wholeseason of mizzle. You'll want to pack an umbrella, or maybe even a snorkel.\n",
      "The average temperature in June is around 25 degrees Celsius (77 degrees Fahrenheit), with high humidity. It can feel pretty hot and sticky, especially when it's not raining.\n",
      "But don't worry, the rain isn't necessarily a bad thing. It's a great time to see Taiwan's beautiful waterfalls and lush green landscapes in all their glory. Just be prepared for a wet and wild adventure!\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "llm = ChatNVIDIA(model=\"meta/llama2-70b\", max_tokens=500) \n",
    "result = llm.invoke(\"What is the weather in Taiwan like in June?\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c6963af5-1052-4cff-a40a-3c140d111376",
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluate essay with text only\n",
    "def evaluate_essay(essay_text):\n",
    "    # Set up the language model\n",
    "#    llm = OpenAI(temperature=0.1)\n",
    "\n",
    "    # Define a prompt template for the essay evaluation\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"essay\"],\n",
    "        template=\"\"\" Please evaluate the quality of the following essay:\n",
    "\n",
    "        {essay}\n",
    "\n",
    "        Provide a detailed analysis of the essay's strengths and weaknesses, including an overall quality score on a scale of 1 to 10.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Generate the essay evaluation using the language model\n",
    "    result = llm(prompt.format(essay=essay_text))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "467dd53f-3329-40f3-a63e-ef617917bb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hcchou\\AppData\\Local\\anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid message: ' ' of type <class 'str'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m##long text for essay, SyntaxError: unterminated string literal  use file link instead\u001b[39;00m\n\u001b[0;32m      2\u001b[0m essay_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is the text of the essay you want to evaluate.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m evaluation \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_essay\u001b[49m\u001b[43m(\u001b[49m\u001b[43messay_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(evaluation)\n",
      "Cell \u001b[1;32mIn[34], line 17\u001b[0m, in \u001b[0;36mevaluate_essay\u001b[1;34m(essay_text)\u001b[0m\n\u001b[0;32m      6\u001b[0m prompt \u001b[38;5;241m=\u001b[39m PromptTemplate(\n\u001b[0;32m      7\u001b[0m     input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124messay\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      8\u001b[0m     template\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m Please evaluate the quality of the following essay:\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Generate the essay evaluation using the language model\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43messay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43messay_text\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:148\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    146\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     emit_warning()\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:847\u001b[0m, in \u001b[0;36mBaseChatModel.__call__\u001b[1;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;129m@deprecated\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.1.7\u001b[39m\u001b[38;5;124m\"\u001b[39m, alternative\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvoke\u001b[39m\u001b[38;5;124m\"\u001b[39m, removal\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.3.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    840\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    841\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    846\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m--> 847\u001b[0m     generation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m    848\u001b[0m         [messages], stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    849\u001b[0m     )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(generation, ChatGeneration):\n\u001b[0;32m    851\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:456\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    455\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 456\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    457\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    458\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    460\u001b[0m ]\n\u001b[0;32m    461\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:446\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    445\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 446\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    447\u001b[0m                 m,\n\u001b[0;32m    448\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    449\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    450\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    451\u001b[0m             )\n\u001b[0;32m    452\u001b[0m         )\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:671\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    670\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 671\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    672\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    673\u001b[0m         )\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    675\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\langchain_nvidia_ai_endpoints\\chat_models.py:210\u001b[0m, in \u001b[0;36mChatNVIDIA._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate\u001b[39m(\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    205\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    209\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[1;32m--> 210\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_custom_preprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m     responses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_generation(inputs\u001b[38;5;241m=\u001b[39minputs, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_callback_out(responses, run_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\langchain_nvidia_ai_endpoints\\chat_models.py:251\u001b[0m, in \u001b[0;36mChatNVIDIA._custom_preprocess\u001b[1;34m(self, msg_list)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_custom_preprocess\u001b[39m(  \u001b[38;5;66;03m# todo: remove\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m, msg_list: Sequence[BaseMessage]\n\u001b[0;32m    250\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]:\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_msg(m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m msg_list]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\langchain_nvidia_ai_endpoints\\chat_models.py:251\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_custom_preprocess\u001b[39m(  \u001b[38;5;66;03m# todo: remove\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m, msg_list: Sequence[BaseMessage]\n\u001b[0;32m    250\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]:\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_preprocess_msg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m msg_list]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\langchain_nvidia_ai_endpoints\\chat_models.py:294\u001b[0m, in \u001b[0;36mChatNVIDIA._preprocess_msg\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    292\u001b[0m     content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_content(msg\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: role, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: content}\n\u001b[1;32m--> 294\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid message: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(msg)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(msg)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid message: ' ' of type <class 'str'>"
     ]
    }
   ],
   "source": [
    "##long text for essay, SyntaxError: unterminated string literal  use file link instead\n",
    "## essay_text = \"This is the text of the essay you want to evaluate.\"\n",
    "## evaluation = evaluate_essay(essay_text)\n",
    "## print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862053dc-1d90-4308-b923-63506597b38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use file path of the essay\n",
    "\n",
    "import os\n",
    "import PyPDF2\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_nvidia_ai_endpoints.chat_models import ChatNVIDIA\n",
    "from langchain.schema import AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2124c0-34c7-42e9-aaf8-f934d0d2ad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_text_from_pdf(pdf_file_path):\n",
    "    with open(pdf_file_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        essay_text = ''\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            essay_text += page.extract_text()\n",
    "    return essay_text\n",
    "\n",
    "def evaluate_essay_quality(pdf_file_path):\n",
    "    # Extract text from PDF file\n",
    "    essay_text = extract_text_from_pdf(pdf_file_path)\n",
    "\n",
    "    # Set up the language model\n",
    "    llm = ChatNVIDIA(model=\"meta/llama2-70b\", max_tokens=1000, temperature=0)\n",
    "\n",
    "    # Define a prompt template for the essay evaluation\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"essay\"],\n",
    "        template=\"\"\"\n",
    "        Please evaluate the quality of the following essay:\n",
    "\n",
    "        {essay}\n",
    "\n",
    "        Provide a detailed analysis of the strengths and weaknesses of the essay, and give an overall quality score on a scale of 1 to 10.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Generate the essay evaluation using the language model\n",
    "    result = llm([AIMessage(content=prompt.format(essay=essay_text))])\n",
    "\n",
    "    return result.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85df17fb-24b3-4d2c-ae86-e3b453336ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "pdf_file_path = '/Users/hchou/Downloads/Essays and Evaluations/#1/Essay#1.pdf'\n",
    "evaluation = evaluate_essay_quality(pdf_file_path)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd85da37-fba5-4d6a-8ed4-0e5bc7e97732",
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluated by a stricted technical background teacher\n",
    "\n",
    "def evaluate_essay_quality_s(pdf_file_path):\n",
    "    # Extract text from PDF file\n",
    "    essay_text = extract_text_from_pdf(pdf_file_path)\n",
    "\n",
    "    # Set up the language model\n",
    "    llm = ChatNVIDIA(model=\"meta/llama2-70b\", max_tokens=1000, temperature=0)\n",
    "\n",
    "    # Define a prompt template for the essay evaluation\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"essay\"],\n",
    "        template=\"\"\"\n",
    "        As a strict technical background teacher, I will provide a thorough evaluation of the following essay:\n",
    "\n",
    "    {essay}\n",
    "\n",
    "    The essay will be assessed on the following criteria:\n",
    "    - Clarity and conciseness of the writing\n",
    "    - Logical flow and organization of the content\n",
    "    - Appropriate use of technical terms and concepts\n",
    "    - Depth of understanding and analysis of the subject matter\n",
    "    - Overall effectiveness in conveying the key points\n",
    "\n",
    "    Please note that I will be evaluating this essay with a critical eye and a focus on technical excellence, and give an overall quality score on a scale of 1 to 10.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Generate the essay evaluation using the language model\n",
    "    result_s = llm([AIMessage(content=prompt.format(essay=essay_text))])\n",
    "\n",
    "    return result_s.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59351063-6e73-48d6-bf1a-c83a0f235e91",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (428183186.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[13], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    pdf_file_path = '/Users/hchou/Downloads/Essays and Evaluations/#1/Essay#2.pdf\"\u001b[0m\n\u001b[0m                                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "## evaluate another essay\n",
    "pdf_file_path = '/Users/hchou/Downloads/Essays and Evaluations/#1/Essay#2.pdf\"\n",
    "evaluation = evaluate_essay_quality(pdf_file_path)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a4fb721-bd18-4bba-a2d7-cfef8de1e81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hcchou\\AppData\\Local\\anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> The essay is well-structured and easy to follow, with a clear introduction, body, and conclusion. The writer effectively uses transitions to connect their ideas and provides a clear thesis statement that guides the reader through the essay. The essay also demonstrates a good understanding of the topic, with the writer effectively using technical terms and concepts to support their arguments.\n",
      "\n",
      "However, there are some areas where the essay could be improved. Firstly, the introduction could be stronger. While the writer does a good job of introducing the topic and providing some background information, they could do more to engage the reader and provide a clearer sense of the essay's focus. Additionally, some of the sentences could be shorter and more concise, making the essay easier to read.\n",
      "\n",
      "Furthermore, while the writer effectively uses technical terms and concepts, there are some instances where they could be more precise in their language. For example, the writer uses the term \"train gap\" to refer to the gap between the train and the platform, but they could also use more specific terms such as \"platform gap\" or \"train-platform gap\" to avoid confusion.\n",
      "\n",
      "Lastly, the essay could benefit from more detailed explanations and examples. While the writer provides some examples of how the gap between the train and the platform can be a problem, they could go into more detail to make their arguments more convincing. Additionally, the writer could provide more specific data or statistics to support their claims.\n",
      "\n",
      "Overall, I would give this essay a score of 7 out of 10. While it is well-structured and demonstrates a good understanding of the topic, there is room for improvement in terms of language precision, sentence structure, and the provision of more detailed explanations and examples.\n"
     ]
    }
   ],
   "source": [
    "# essay2 evaluated by a strict technology teacher\n",
    "pdf_file_path = 'C:/Users/hcchou/Downloads/Nvidia contest/Essay#2.pdf'\n",
    "evaluation = evaluate_essay_quality_s(pdf_file_path)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f2c85b5-c5c9-45f6-bdbb-7db1b4457121",
   "metadata": {},
   "outputs": [],
   "source": [
    "## debate take 2\n",
    "## debate file in pdf\n",
    "\n",
    "## try\n",
    "def evaluate_essay_quality(pdf_file_path):\n",
    "    # Extract text from PDF file\n",
    "    essay_text = extract_text_from_pdf(pdf_file_path)\n",
    "\n",
    "    # Set up the language model\n",
    "    llm = ChatNVIDIA(model=\"meta/llama2-70b\", max_tokens=1000, temperature=0)\n",
    "\n",
    "    # Define a prompt template for the essay evaluation\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"essay\"],\n",
    "        template=\"\"\"\n",
    "        Please evaluate the quality of the following essay:\n",
    "\n",
    "        {essay}\n",
    "\n",
    "        Provide a detailed analysis of the strengths and weaknesses of the essay, and give an overall quality score on a scale of 1 to 10.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Generate the essay evaluation using the language model\n",
    "    result = llm([AIMessage(content=prompt.format(essay=essay_text))])\n",
    "\n",
    "    return result.content\n",
    "\n",
    "def debate_with_llm(pdf_ev_file_path, human_opinion):\n",
    "    # Extract text from PDF file\n",
    "    llm_response = extract_text_from_pdf(pdf_ev_file_path)\n",
    "    \n",
    "    # Set up the language model\n",
    "    llm = ChatNVIDIA(model=\"meta/llama2-70b\", max_tokens=1000, temperature=0)\n",
    "\n",
    "    # Define prompt template\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"llm_evaluation\", \"human_opinion\"],\n",
    "        template=\"\"\"\n",
    "        The language model has provided the following evaluation:\n",
    "\n",
    "        {llm_evaluation}\n",
    "\n",
    "        As a human teacher has given opinion on the essay:\n",
    "\n",
    "        {human_opinion}\n",
    "\n",
    "        The human teacher would like you to revise your evaluation. Please add human teacher's opinion and summary the evaluation in 200 words. Revise and give an overall quality score on a scale of 1 to 10.\n",
    "        \"\"\"\n",
    "    )\n",
    "    human_response = llm([AIMessage(content=prompt.format(llm_evaluation=llm_response, human_opinion=human_opinion))])\n",
    "    return human_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1706b22-7ff3-4b5f-8872-f908cfbcdc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> The revised evaluation should include the following:\n",
      "\n",
      "1. A clear thesis statement that summarizes the main point of the essay.\n",
      "2. More concise sentences that are easier to understand.\n",
      "3. More specific examples of the author's contributions to the project, such as detailed descriptions of their designs and how they addressed the problem of the train gap.\n",
      "4. More detailed feedback and analysis of the author's designs and ideas.\n",
      "5. A more critical evaluation of the project's successes and limitations.\n",
      "\n",
      "Here is a revised evaluation of the essay:\n",
      "\n",
      "The essay provides a detailed description of the author's experience in a class project, where they designed mechanisms to fill the gap between a train and a station platform. The author reflects on what they learned from the class, including collaboration, communication, and critical thinking skills, and how they applied these skills in the project. The essay is well-organized and easy to follow, with a clear introduction, body, and conclusion. The author uses appropriate technical vocabulary and explanations to describe their designs and ideas.\n",
      "\n",
      "However, the essay lacks a clear thesis statement that summarizes the main point of the essay. Some sentences are long and convoluted, making them difficult to understand. The author could have provided more specific examples of their contributions to the project, such as detailed descriptions of their designs and how they addressed the problem of the train gap. Additionally, the essay could benefit from more detailed feedback and analysis of the author's designs and ideas, as well as a more critical evaluation of the project's successes and limitations.\n",
      "\n",
      "Overall, I would rate the essay a 8 out of 10. The author demonstrates a good understanding of the topic and the potential of extending the result further. The essay is well-organized and easy to follow, and the author uses appropriate technical vocabulary and explanations. However, the essay could benefit from a clearer thesis statement, more concise sentences, and more specific examples of the author's contributions to the project.\n",
      "\n",
      "Here is a summary of the evaluation in 200 words:\n",
      "\n",
      "The essay provides a detailed description of the author's experience in a class project, where they designed mechanisms to fill the gap between a train and a station platform. The author reflects on what they learned from the class, including collaboration, communication, and critical thinking skills, and how they applied these skills in the project. The essay is well-organized and easy to follow, with a clear introduction, body, and conclusion. The author uses appropriate technical vocabulary and explanations to describe their designs and ideas. However, the essay lacks a clear thesis statement that summarizes the main point of the essay. Some sentences are long and convoluted, making them difficult to understand. The author could have provided more specific examples of their contributions to the project, such as detailed descriptions of their designs and how they addressed the problem of the train gap. Additionally, the essay could benefit from more detailed feedback and analysis of the author's designs and ideas, as well as a more critical evaluation of the project's successes and limitations. Overall, I would rate the essay a 8 out of 10.\n"
     ]
    }
   ],
   "source": [
    "pdf_ev_file_path = '/Users/hchou/Downloads/Essays and Evaluations/#1/Essay#1_llm_ev.pdf'\n",
    "\n",
    "human_opinion = \"\"\"\n",
    "As a human teacher, I agree with your opinion. Yet I believe the author demonstrates a good understanding of the topic and the potential of extending the result further. \n",
    "\n",
    "Overall, I would rate the essay a 8 out of 10.\n",
    "\"\"\"\n",
    "\n",
    "human_response = debate_with_llm(pdf_ev_file_path, human_opinion)\n",
    "\n",
    "print(human_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630d128e-030f-4bf9-b839-e88785203cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coversation chain : discussion take 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5adaba0d-db3e-41d6-b305-949846c98bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.pdf import PyMuPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37550a0-f5ce-485b-b584-b404380c02a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb958722-752a-4b1a-be4c-6d5456bcd561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4611e857-3855-48f1-9008-1f1c4396c128",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compare two essays, tried manytimes, it seems the model can not take two pdf inputs.\n",
    "\n",
    "def compare_essay_quality(pdf_file_path1, pdf_file_path2):\n",
    "    # Extract text from PDF file 1\n",
    "    with open(pdf_file_path1, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        essay_text1 = ''\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            essay_text1 += page.extract_text()\n",
    "\n",
    "    # Extract text from PDF file 2\n",
    "    with open(pdf_file_path2, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        essay_text2 = ''\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            essay_text2 += page.extract_text()\n",
    "\n",
    "    # Set up the language model\n",
    "    llm = ChatNVIDIA(model=\"meta/llama2-70b\", max_tokens=2000, temperature=0)\n",
    "\n",
    "    # Define a prompt template for the comparative essay evaluation\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"essay1\", \"essay2\"],\n",
    "        template=\"\"\"\n",
    "        Please analysis which essay has better quality.\n",
    "\n",
    "        Essay 1:\n",
    "        {essay1}\n",
    "\n",
    "        Please evaluate the quality of the following essay:\n",
    "\n",
    "        Essay 2:\n",
    "        {essay2}\n",
    "\n",
    "        # Provide the strengths and weaknesses of each essay with under 200 words each, and give an overall quality score for each essay on a scale of 1 to 10. Conclude with a recommendation on which essay has the higher quality.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Generate the comparative essay evaluation using the language model\n",
    "    result_c = llm(prompt.format(essay1=essay_text1, essay2=essay_text2))\n",
    "\n",
    "    return result_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c864a19c-fb5d-4eb1-a57f-aeb6161cfd71",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid message: '\\n' of type <class 'str'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m pdf_file_path1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/hcchou/Downloads/Nvidia contest/Essay#1.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m pdf_file_path2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/hcchou/Downloads/Nvidia contest/Essay#2.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m comparison_c \u001b[38;5;241m=\u001b[39m \u001b[43mcompare_essay_quality\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_file_path1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpdf_file_path2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(comparison)\n",
      "Cell \u001b[1;32mIn[8], line 42\u001b[0m, in \u001b[0;36mcompare_essay_quality\u001b[1;34m(pdf_file_path1, pdf_file_path2)\u001b[0m\n\u001b[0;32m     24\u001b[0m prompt \u001b[38;5;241m=\u001b[39m PromptTemplate(\n\u001b[0;32m     25\u001b[0m     input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124messay1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124messay2\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     26\u001b[0m     template\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     39\u001b[0m )\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Generate the comparative essay evaluation using the language model\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m result_c \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43messay1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43messay_text1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43messay2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43messay_text2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result_c\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:148\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    146\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     emit_warning()\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:847\u001b[0m, in \u001b[0;36mBaseChatModel.__call__\u001b[1;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;129m@deprecated\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.1.7\u001b[39m\u001b[38;5;124m\"\u001b[39m, alternative\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvoke\u001b[39m\u001b[38;5;124m\"\u001b[39m, removal\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.3.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    840\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    841\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    846\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m--> 847\u001b[0m     generation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m    848\u001b[0m         [messages], stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    849\u001b[0m     )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(generation, ChatGeneration):\n\u001b[0;32m    851\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:456\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    455\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 456\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    457\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    458\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    460\u001b[0m ]\n\u001b[0;32m    461\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:446\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    445\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 446\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    447\u001b[0m                 m,\n\u001b[0;32m    448\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    449\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    450\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    451\u001b[0m             )\n\u001b[0;32m    452\u001b[0m         )\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:671\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    670\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 671\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    672\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    673\u001b[0m         )\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    675\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\langchain_nvidia_ai_endpoints\\chat_models.py:210\u001b[0m, in \u001b[0;36mChatNVIDIA._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate\u001b[39m(\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    205\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    209\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[1;32m--> 210\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_custom_preprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m     responses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_generation(inputs\u001b[38;5;241m=\u001b[39minputs, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_callback_out(responses, run_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\langchain_nvidia_ai_endpoints\\chat_models.py:251\u001b[0m, in \u001b[0;36mChatNVIDIA._custom_preprocess\u001b[1;34m(self, msg_list)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_custom_preprocess\u001b[39m(  \u001b[38;5;66;03m# todo: remove\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m, msg_list: Sequence[BaseMessage]\n\u001b[0;32m    250\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]:\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_msg(m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m msg_list]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\langchain_nvidia_ai_endpoints\\chat_models.py:251\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_custom_preprocess\u001b[39m(  \u001b[38;5;66;03m# todo: remove\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m, msg_list: Sequence[BaseMessage]\n\u001b[0;32m    250\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]:\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_preprocess_msg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m msg_list]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\langchain_nvidia_ai_endpoints\\chat_models.py:294\u001b[0m, in \u001b[0;36mChatNVIDIA._preprocess_msg\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    292\u001b[0m     content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_content(msg\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: role, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: content}\n\u001b[1;32m--> 294\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid message: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(msg)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(msg)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid message: '\\n' of type <class 'str'>"
     ]
    }
   ],
   "source": [
    "pdf_file_path1 = 'C:/Users/hcchou/Downloads/Nvidia contest/Essay#1.pdf'\n",
    "pdf_file_path2 = 'C:/Users/hcchou/Downloads/Nvidia contest/Essay#2.pdf'\n",
    "comparison_c = compare_essay_quality(pdf_file_path1, pdf_file_path2)\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887bff63-cf44-49ae-ae47-cbf93dff2a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
